# KNN y CART

## Lectura

- Conceptos generales
    - [Model-Agnostic Methods (_Interpretable Machine Learning_: Cap. 6)](https://christophm.github.io/interpretable-ml-book/agnostic.html)
    - [Example-Based Explanations (_Interpretable Machine Learning_: Cap. 7)](https://christophm.github.io/interpretable-ml-book/example-based.html)

- KNN
    - [K-Nearest Neighbors  (_Introduction to Statistical Learning_: pág. 39 a 42)](https://hastie.su.domains/ISLR2/ISLRv2_website.pdf)
    - [Nearest Neighbors (_sklearn User Guide_)](https://scikit-learn.org/stable/modules/neighbors.html)
    - [The k-Nearest Neighbors (kNN) Algorithm in Python (_Real Python site_)](https://realpython.com/knn-python/)
    - [Comparison of Linear Regression with K-Nearest Neighbors (_Introduction to Statistical Learning_: pág. 105 a 110)](https://hastie.su.domains/ISLR2/ISLRv2_website.pdf)

- CART
    - [Decision Tree (_Interpretable Machine Learning_: Cap. 5.4)](https://christophm.github.io/interpretable-ml-book/tree.html)
    - [Tree-Based Methods (_Introduction to Statistical Learning_: pág. 327 a 339)](https://hastie.su.domains/ISLR2/ISLRv2_website.pdf)
    - [Decision Trees (_sklearn User Guide_)](https://scikit-learn.org/stable/modules/tree.html)
    - [Árboles de Decisión y Random Forest](https://bookdown.org/content/2031/)

## Actividades

- (<span style="color:red">**ENTREGA OBLIGATORIA**</span>) Considere el dataset [Real State Pricing](https://drive.google.com/drive/folders/1Lprg5DfAXRnUcmYi5TdzfpKIzQ49ITuq?usp=share_link) y asuma que es resultado de un muestreo aleatorio en determinada zona urbana. Estime el precio (por unidad de superficie) de las casas usando KNN y CART. Realice las transformaciones de datos que considere necesarias. Compare los resultados con los modelos previamente realizados (regresión lineal y logística). Utilice la librería _sklearn_ de Python para el desarrollo de este análisis. El entregable de este trabajo debe ser una Jupyter notebook con los siguientes apartados: EDA, transformación de los datos, construcción de los modelos, comparación de resultados y conclusiones.

## Resumen

Estos modelos, **aplicables tanto para regresión como clasificación**, son excelentes aproximaciones a los datos, sin contar necesariamente con conocimiento previo de su comportamiento ni realizar suposiciones acerca del modelo subyacente. Son útiles tanto en la etapa de **exploración de datos** o para construir **modelos de base** (porque en la práctica no son los suficimiente performantes como para implementar de manera productiva, por tanto sirven como punto de comparación para construir modelos que los superen).

Al igual que la regresión lineal y logística, sus resultados **son interpretables**, aunque no cuentan con parámetros estimados que puedan analizarse posteriormente. Para el caso de los árboles de decisión, cuentan además con la ventaja de poder **ingestar cualquier tipo de datos**, ya que, en esencia, son reglas de "si o no" en función del poder discriminativo de los datos disponibles. En ese sentido, siendo que dependen exclusivamente de los datos, son muy sensibles a la calidad de los mismos y además al azar respecto al punto de partida seteado por el analista. Por tanto, debe tenerse en cuenta **no establecer conclusiones apresuradas** solamente a partir de estos modelos.

Más adelante se verá que éstos son bloques a partir de los cuales se pueden construir modelos más complejos (muy utilizados en la industria, como _random forests_), con las mismas características, pero salvando las desventajas mencionadas.
.