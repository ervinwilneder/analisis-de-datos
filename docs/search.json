[
  {
    "objectID": "07 - probabilidad aplicada.html",
    "href": "07 - probabilidad aplicada.html",
    "title": "Probabilidad aplicada",
    "section": "",
    "text": "Lectura\n\nEpílogo: Estadística y Probabilidad (Estadística para Todos: pág. 245 a 247)\nEstudio de los conceptos de la probabilidad (Estadística Aplicada a los Negocios y la Economía: pág. 144 a 151)\nDistribuciones de Probabilidad Discreta (Estadística Aplicada a los Negocios y la Economía: pág. 186 a 202)\nDistribuciones de Probabilidad Continua (Estadística Aplicada a los Negocios y la Economía: pág. 222 a 242)\nProbability (STAT 500 | Applied Statistics: lesson 2)\nProbability Distributions (STAT 500 | Applied Statistics: lesson 3)\nSampling Distributions (STAT 500 | Applied Statistics: lesson 4)\n\n\n\nActividades\n\nConsidere el dataset Pokemon. Proponga 3 experimentos sobre dicha población para obtener como resultado una variable aleatoria cuya distribución sea: (1) binomial, (2) normal y (3) chi cuadrado.\nResponda las siguientes preguntas:\n\n¿Cuál es la probabilidad de obtener un pokemon cuya velocidad sea mayor a 100?\n¿Cuál es la probabilidad de obtener un pokemon cuyo ataque sea igual a 60?\n¿Cuál es la probabilidad de obtener un pokemon de aire al realizar una muestra aleatoria de 10 pokemones?\n¿Cuál es la probabilidad de obtener un pokemon de generación 3 al seleccionar un sólo pokemon?\nDado que un pokemon es de tierra, ¿cuál es la probabilidad que su defensa sea menor a 50?\n¿Cuál es la probabilidad de obtener un pokemon de tierra y con defensa menor a 50?\n¿Cuál es la probabilidad de que un pokemon sea de tierra suponiendo que en una muestra de 10 unidades obtuvo sólo 1 pokemon de este tipo?\n\n\n\n\nResumen\nLa probabilidad es una herramienta fundamental para el análisis de datos, no tanto por su uso directo, sino porque es el sustento matemático de muchas demostraciones de procesos y fórmulas que habitualmente se aplican. Por tanto, conocer los conceptos y definiciones básicos es una puerta a comprender mejor tanto el análisis como las conclusiones obtenidas.\nSerá particularmente útil asimilar las distribuciones más relevantes que surgen como resultado del análisis de variables aleatorias; éstas son: la distribución binomial, la distribución normal y la distribución chi-cuadrado. Cada una estará asociada al estudio de medidas de posición, dispersión y relación, vistas anteriormente. Es decir, estas medidas, si se dan las adecuadas condiciones, tendrán un comportamiento teóricamente definido y demostrado, lo cual posibilita enormemente su análisis. También será útil el conocimiento y cálculo de probabilidades conjuntas y condicionales, habituales en el análisis multivariado.\nA continuación un ejemplo, realizado en python, de cómo se construye la distribución de una media muestral. Prestar atención particularmente a la forma final de la curva. Tener en cuenta además que la misma dependerá de factores como la cantidad de muestras y el tamaño de éstas.\nInicialmente se ingestan los datos y se calcula la media para la variable speed.\n\nimport pandas as pd\n\ndata = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vRMQoYDMXx2r2fIUhy0JbiDI6UyWwTPLEx_mAeXgxEnFikqYu-k0l2BgCv8y_QPsrpWBNSdn8SZBeuT/pub?gid=969789387&single=true&output=csv')\ndisplay(data[['name', 'speed']])\n\nprint('La media de la velocidad es: ', data['speed'].mean())\n\n\n\n\n\n  \n    \n      \n      name\n      speed\n    \n  \n  \n    \n      0\n      Bulbasaur\n      45\n    \n    \n      1\n      Ivysaur\n      60\n    \n    \n      2\n      Venusaur\n      80\n    \n    \n      3\n      VenusaurMega Venusaur\n      80\n    \n    \n      4\n      Charmander\n      65\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      795\n      Diancie\n      50\n    \n    \n      796\n      DiancieMega Diancie\n      110\n    \n    \n      797\n      HoopaHoopa Confined\n      70\n    \n    \n      798\n      HoopaHoopa Unbound\n      80\n    \n    \n      799\n      Volcanion\n      70\n    \n  \n\n800 rows × 2 columns\n\n\n\nLa media de la velocidad es:  68.2775\n\n\nAl tomar una muestra de 100 unidades, el resultado es bastante cercano al valor obtenido previamente. Éste valor, como se ha mencionado anteriormente, variará de muestra en muestra.\n\nprint('La media MUESTRAL de la velocidad es: ', data['speed'].sample(100).mean())\n\nLa media MUESTRAL de la velocidad es:  65.35\n\n\nAhora bien, al realizar varias muestras sucesivas, por ejemplo 100, obtendremos un conjunto de valores de medias muestrales que podemos representar gráficamente.\n\nmedias_muestrales = []\n\nfor muestra in range(100):\n  media_muestral = data['speed'].sample(100).mean()\n  medias_muestrales.append(media_muestral)\n\npd.DataFrame(medias_muestrales, columns=['Distribución de la media muestral para la velocidad']).hist(bins=30, grid=False);\n\n\n\n\nSe observan que la mayoría de los valores se hayan en los alrededores de la media calculada inicialmente. Esta situación se presenta incluso si faltase una única unidad en el muestreo.\n\nmedias_muestrales = []\n\nfor muestra in range(100):\n  media_muestral = data['speed'].sample(799).mean()\n  medias_muestrales.append(media_muestral)\n\npd.DataFrame(medias_muestrales, columns=['Distribución de la media muestral para la velocidad']).hist(bins=30, grid=False);\n\n\n\n\nAl incrementar la cantidad de repeticiones, sucede lo siguiente:\n\nmedias_muestrales = []\n\nfor muestra in range(10000):\n  media_muestral = data['speed'].sample(100).mean()\n  medias_muestrales.append(media_muestral)\n\npd.DataFrame(medias_muestrales, columns=['Distribución de la media muestral para la velocidad']).hist(bins=30, grid=False);\n\n\n\n\nVisualmente podemos concluir que, dado que se obtuviese una muestra de 100 unidades del conjunto de datos, es muy probable que el valor de la media calculado se encuentre entre 62 y 75. Esta conclusión podrá ser extendida al cálculo de cualquier media muestral y tomar valores determinados.\nEl proceso por el cual se llega a dichos valores se denomina estimación y es lo que se verá en el próximo capítulo."
  },
  {
    "objectID": "08 - estimacion puntual y por intervalos.html",
    "href": "08 - estimacion puntual y por intervalos.html",
    "title": "Estimación puntual y por intervalos de confianza",
    "section": "",
    "text": "Lectura\n\nEstimación y parámetros (Estadística para Todos: pág. 55)\nVariabilidad entre muestra y muestra (Estadística para Todos: pág. 58 a 63)\nTeorema Central del Límite (Estadística para Todos: pág. 200 a 207)\nDistribuciones de muestreo de estadísticas (Probabilidad y Estadística | Aplicaciones y Métodos: pág. 218 a 238)\nEstimación por intervalos (Estadística para Todos: pág. 214 a 228)\nEstimación e intervalos de confianza (Estadística Aplicada a los Negocios y la Economía: pág. 297 a 315)\nPropiedades deseables de los estimadores puntuales (Probabilidad y Estadística | Aplicaciones y Métodos: pág. 251 a 261)\nConfidence Intervales (STAT 500 | Applied Statistics: lesson 5)\n\n\n\nActividades\n\nConsidere el dataset Pokemon y asuma que es el listado completo de todos los pokemones (es decir, la población). Use los parámetros obtenidos previamente y vuelva a calcular estimadores (utilizando las fórmulas adecuadas para cada caso, vistas en esta sección) pero realizando muestras aleatorias de manera sucesiva. Realice este mismo procedimiento con muestras de diferente tamaño. Grafique la distribución de los estimadores y saque conclusiones.\nRetome lo realizado en la anterior clase y estime nuevamente los valores de media, varianza y proporción para las variables seleccionadas, utilizando diferentes niveles de confianza. Escriba una breve reseña con conclusiones acerca de los resultados obtenidos."
  },
  {
    "objectID": "09 - tests de hipotesis.html",
    "href": "09 - tests de hipotesis.html",
    "title": "Tests de hipótesis",
    "section": "",
    "text": "Lectura\n\nDecisiones en el campo de la estadística (Estadística para Todos: pág. 231 a 241)\nPruebas de hipótesis de una muestra (Estadística Aplicada a los Negocios y la Economía: pág. 333 a 346)\nPruebas de hipótesis estadísticas (Probabilidad y Estadística | Aplicaciones y Métodos: pág. 303 a 346)\nHypothesis Testing for One-Sample Proportion (STAT 500 | Applied Statistics: lesson 6a)\nHypothesis Testing for One-Sample Mean (STAT 500 | Applied Statistics: lesson 6b)\n\n\n\nActividades:\n\nConsidere el dataset Breast Cancer Data. Asuma que es resultado de un muestreo aleatorio, llevado a cabo en el marco de una investigación, y responda/realice lo siguiente:\n\nDefina población y unidad de análisis.\nDetalle las posibles características del procedimiento de muestreo llevado adelante.\nRealice un breve análisis exploratorio.\nPlantee al menos 3 preguntas relevantes para la investigación y que puedan ser respondidas a partir de dichos datos.\nA partir de las preguntas, defina las pruebas de hipótesis correspondientes y calcule los estimadores necesarios.\n\n(ENTREGA OBLIGATORIA) Vuelque todo lo anterior en un informe (máx. 10 páginas). Incluya:\n\nUn resumen del trabajo realizado a modo de introducción, considerando supuestos, planteamientos y resultados.\nUna sección con el análisis de los datos y procedimientos correspondientes. Explique y justifique cada paso.\nUn apartado final donde exponga conclusiones acerca de su trabajo, formule interrogantes acerca de la validez de sus conclusiones y presente posibles caminos de acción para subsanar/mejorar/ampliar la investigación."
  },
  {
    "objectID": "10 - estadistica no parametrica.html",
    "href": "10 - estadistica no parametrica.html",
    "title": "Estadística NO paramétrica",
    "section": "",
    "text": "Lectura\n\nPrueba sobre la mediana\n\nPrueba de los signos (Estadística Aplicada a los Negocios y la Economía: pág. 681 a 685)\nInference for the Population Median (STAT 500 | Applied Statistics: lesson 11.1)\nDistribution-Free Confidence Intervals for Percentiles (STAT 415 | Introduction to Mathematical Statistics: lesson 19)\n\n\n\nPruebas sobre distribuciones (bondad de ajuste / independencia / aleatoriedad)\n\nMétodos no paramétricos: pruebas de bondad de ajuste (Estadística Aplicada a los Negocios y la Economía: pág. 648 a 658)\nPrueba de hipótesis de que la distribución de datos proviene de una población normal (Estadística Aplicada a los Negocios y la Economía: pág. 659 a 664)\nAnálisis de tablas de contingencia (Estadística Aplicada a los Negocios y la Economía: pág. 667 a 670)\nLa prueba de bondad de ajuste chi-cuadrada (Probabilidad y Estadística | Aplicaciones y Métodos: pág. 363 a 368)\nLa estadística de Kolmogorov-Smirnov (Probabilidad y Estadística | Aplicaciones y Métodos: pág. 368 a 370)\nChi-Square Test for Independence (STAT 500 | Applied Statistics: lesson 8)\nChi-Square Goodness-of-Fit Tests (STAT 415 | Introduction to Mathematical Statistics: lesson 16)\nContingency Tables (STAT 415 | Introduction to Mathematical Statistics: lesson 17)\nThe Wilcoxon Tests (STAT 415 | Introduction to Mathematical Statistics: lesson 20)\nRun Test and Test for Randomness (STAT 415 | Introduction to Mathematical Statistics: lesson 21)\nKolmogorov-Smirnov Goodness-of-Fit Test (STAT 415 | Introduction to Mathematical Statistics: lesson 22)\n\n\n\nBootstrapping\n\nIntroduction to Bootstrapping (STAT 500 | Applied Statistics: lesson 11.2)\nBootstrapping Main Ideas!!! (StatQuest YouTube Channel)\n\n\n\n\nActividades\n\nConsidere el dataset Wendy’s Menu Nutrition Data. Asuma que es resultado de un muestreo aleatorio de productos y responda/realice lo siguiente:\n\nRealice la prueba de Kolmogorov-Smirnov sobre todas las variables y concluya cuáles de ellas no tienen distribución normal. Complemente con métodos gráficos si considera necesario.\nUtilizando el método de boostrapping, lleve adelante la estimación de media, mediana y desviación estándar para todas aquellas variables.\nSe ha afirmado que el 50% de los productos tiene más de 800 calorías. ¿Está usted de acuerdo? Evalúe y compare distintos métodos para llegar a una conclusión.\nSe ha afirmado que la valoración de los productos está relacionada a su cantidad de grasa. ¿Está usted de acuerdo? Tenga en cuenta adecuar los datos para poder realizar el correspondiente análisis."
  },
  {
    "objectID": "11 - tecnicas de muestreo.html",
    "href": "11 - tecnicas de muestreo.html",
    "title": "Técnicas de muestreo",
    "section": "",
    "text": "Lectura\n\nMétodos de muestreo (Estadística Aplicada a los Negocios y la Economía: pág. 266 a 271)\nElección del tamaño adecuado de una muestra (Estadística Aplicada a los Negocios y la Economía: pág. 316 a 321)\nEstimating Population Mean and Total under SRS (STAT 506 | Sampling Theory and Methods: lesson 1)\nConfidence Intervals and Sample Size (STAT 506 | Sampling Theory and Methods: lesson 2)\nStratified Sampling (STAT 506 | Sampling Theory and Methods: lesson 6)\nCluster and Systematic Sampling (STAT 506 | Sampling Theory and Methods: lessons 7 y 8)\nMulti-Stage Designs (STAT 506 | Sampling Theory and Methods: lesson 9)\n\n\n\nActividades\n\nConsidere el dataset LinkedIn Freelancer Survey Results. Señale algunos aspectos claves a considerar en la realización de dicha encuesta (¿acaso podría implementarse un muestreo estratificado, por conglomerados o sistemático?) y haga una estimación del tamaño adecuado para la misma.\nConsidere el dataset London Bike Sharing Dataset. Asuma que es el total de registros por hora de viajes en bicicleta hasta el día de la fecha. Realice un análisis exploratorio de la variable cnt (total de viajes), principalmente calculando la media y desvío estándar. Luego, implemente un muestreo sistemático de los datos, estime los paramétros correspondientes y compare. Realice la comparación considerando temporada (season) y fines de semana (weekend)."
  },
  {
    "objectID": "12 - anova.html",
    "href": "12 - anova.html",
    "title": "ANOVA: Análisis de la varianza",
    "section": "",
    "text": "Lectura\n\nAnálisis de la varianza (Estadística Aplicada a los Negocios y la Economía: pág. 410 a 440)\nIntroduction to ANOVA (STAT 500 | Applied Statistics: lesson 10)\n\n\n\nActividades\n\nConsidere el dataset CNC turning Experiment. Identifique aquellos factores para los cuales la media de la fuerza (force), en al menos un grupo, sea significativamente diferente. Evalué en todos los casos los supuestos del análisis. Si para un grupo de factores encuentra diferencias, determine entre cuáles. Concluya cuáles factores son los que determinan la mayor fuerza posible alcanzada.\nLleve adelante una transformación de los datos tal que las réplicas de cada corrida (run_id) pasen a conformar las columnas r1 a r6 y además calcule la media y desvío estándar asociadas a las mismas."
  },
  {
    "objectID": "13 - regresion lineal.html",
    "href": "13 - regresion lineal.html",
    "title": "Regresión Lineal",
    "section": "",
    "text": "Lectura\n\nRelación entre variables (Estadística para Todos: pág. 168 a 196)\nEl estudio de la relación entre variables (Estadística Aplicada a las Ciencias Sociales y Humanas: pág. 105 a 130)\nRegresión lineal y correlación (Estadística Aplicada a los Negocios y la Economía: pág. 461 a 494)\nAnálisis de regresión: el modelo lineal simple (Probabilidad y Estadística | Aplicaciones y Métodos: pág. 443 a 478)\nFundamentals of Data Visualization (Part I: Cap. 12)\nLinear Regression Foundations (STAT 500 | Applied Statistics: lesson 9)\nIntroduction to Modeling Libraries in Python (Python for Data Analysis: cap. 12)\nIn Depth: Linear Regression (Python Data Science Handbook)\n\n\n\nActividades\n\nConsidere el dataset CNC turning Experiment. Identifique aquellos factores para los cuales la media de la fuerza (force), en al menos un grupo, sea significativamente diferente. Evalué en todos los casos los supuestos del análisis. Si para un grupo de factores encuentra diferencias, determine entre cuáles. Concluya cuáles factores son los que determinan la mayor fuerza posible alcanzada.\nLleve adelante una transformación de los datos tal que las réplicas de cada corrida (run_id) pasen a conformar las columnas r1 a r6 y además calcule la media y desvío estándar asociadas a las mismas."
  },
  {
    "objectID": "14 - regresion logistica.html",
    "href": "14 - regresion logistica.html",
    "title": "Regresión Logística",
    "section": "",
    "text": "Lectura\n\nRelación entre variables (Estadística para Todos: pág. 168 a 196)\nEl estudio de la relación entre variables (Estadística Aplicada a las Ciencias Sociales y Humanas: pág. 105 a 130)\nRegresión lineal y correlación (Estadística Aplicada a los Negocios y la Economía: pág. 461 a 494)\nAnálisis de regresión: el modelo lineal simple (Probabilidad y Estadística | Aplicaciones y Métodos: pág. 443 a 478)\nFundamentals of Data Visualization (Part I: Cap. 12)\nLinear Regression Foundations (STAT 500 | Applied Statistics: lesson 9)\nIntroduction to Modeling Libraries in Python (Python for Data Analysis: cap. 12)\nIn Depth: Linear Regression (Python Data Science Handbook)\n\n\n\nActividades\n\nConsidere el dataset CNC turning Experiment. Identifique aquellos factores para los cuales la media de la fuerza (force), en al menos un grupo, sea significativamente diferente. Evalué en todos los casos los supuestos del análisis. Si para un grupo de factores encuentra diferencias, determine entre cuáles. Concluya cuáles factores son los que determinan la mayor fuerza posible alcanzada.\nLleve adelante una transformación de los datos tal que las réplicas de cada corrida (run_id) pasen a conformar las columnas r1 a r6 y además calcule la media y desvío estándar asociadas a las mismas."
  },
  {
    "objectID": "15 - knn y cart.html",
    "href": "15 - knn y cart.html",
    "title": "KNN y CART",
    "section": "",
    "text": "Lectura\n\nRelación entre variables (Estadística para Todos: pág. 168 a 196)\nEl estudio de la relación entre variables (Estadística Aplicada a las Ciencias Sociales y Humanas: pág. 105 a 130)\nRegresión lineal y correlación (Estadística Aplicada a los Negocios y la Economía: pág. 461 a 494)\nAnálisis de regresión: el modelo lineal simple (Probabilidad y Estadística | Aplicaciones y Métodos: pág. 443 a 478)\nFundamentals of Data Visualization (Part I: Cap. 12)\nLinear Regression Foundations (STAT 500 | Applied Statistics: lesson 9)\nIntroduction to Modeling Libraries in Python (Python for Data Analysis: cap. 12)\nIn Depth: Linear Regression (Python Data Science Handbook)\n\n\n\nActividades\n\nConsidere el dataset CNC turning Experiment. Identifique aquellos factores para los cuales la media de la fuerza (force), en al menos un grupo, sea significativamente diferente. Evalué en todos los casos los supuestos del análisis. Si para un grupo de factores encuentra diferencias, determine entre cuáles. Concluya cuáles factores son los que determinan la mayor fuerza posible alcanzada.\nLleve adelante una transformación de los datos tal que las réplicas de cada corrida (run_id) pasen a conformar las columnas r1 a r6 y además calcule la media y desvío estándar asociadas a las mismas."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Análisis de datos I",
    "section": "",
    "text": "Prefacio\nEl presente libro es un compilado de lecturas y actividades sobre diferentes temas que son considerados fundamentales para el análisis de datos. Cada capítulo corresponde a un tema e incluye un resumen con ideas y conclusiones a destacar.\nEste material fue desarrollado exclusivamente para la materia Análisis de Datos I de la Diplomatura Universitaria en Programación de la UTN HAEDO, dictada inicialmente en 2023."
  },
  {
    "objectID": "01 - conceptos y definiciones.html#lectura",
    "href": "01 - conceptos y definiciones.html#lectura",
    "title": "1  Conceptos y definiciones",
    "section": "1.1 Lectura",
    "text": "1.1 Lectura\n\nhttps://aws.amazon.com/es/what-is/data-analytics/\nhttps://www.intel.la/content/www/xl/es/artificial-intelligence/what-is-data-analytics.html\nhttps://www.oracle.com/business-analytics/data-analytics/"
  },
  {
    "objectID": "01 - conceptos y definiciones.html#actividades",
    "href": "01 - conceptos y definiciones.html#actividades",
    "title": "1  Conceptos y definiciones",
    "section": "1.2 Actividades",
    "text": "1.2 Actividades\n\n¿Qué es Data Analytics? ¿Considera que es lo mismo que Análisis de Datos?\n¿En qué se diferencia de Big Data Analytics?\n¿Cuáles son los pasos a seguir en un proceso de análisis de datos?\nMencione al menos 3 herramientas vinculadas al análisis de datos\n¿Qué tipo de análisis de datos se pueden hacer?\nRelacione la anterior respuesta con los siguientes conceptos: raw data, information, knowledge, insight, actionable insight, decision-making, model\nDiferencie brevemente Machine Learning, Data Mining, Data Science, Business Intelligence, Data Analysis y Data Analytics"
  },
  {
    "objectID": "01 - conceptos y definiciones.html#resumen",
    "href": "01 - conceptos y definiciones.html#resumen",
    "title": "1  Conceptos y definiciones",
    "section": "1.3 Resumen",
    "text": "1.3 Resumen\nEl análisis de datos es una actividad que se encuentra integrada a otras como ingeniería y ciencia de datos compartiendo conceptos y herramientas, y habitualmente superponiéndose en el día a día de muchas organizaciones. Por esto mismo, como profesional del área, es importante reconocer cuáles son las incumbencias del análisis de datos y cómo se relaciona con el resto del ciclo de vida de los datos.\nSurge entonces la necesidad de definir y comprender conceptos fundamentales para lograr esa distinción. Como suele suceder en otros rubros, varios de estos conceptos son asimilados del inglés y se utilizan diariamente de esta manera, lo que contribuye a la confunsión en algunos casos. Además, las definiciones no siempre son unísonas: dependen de cada autor y evolucionan en el tiempo. Implica así una capacitación y actualización constante.\nComo actividad, el análisis de datos requiere principalmente conocimientos de estadística y de dominio (o de negocio), de tal manera de poder trabajar los datos, obtener conclusiones y traducir esas conclusiones en recomendaciones o acciones (o simplemente producir información / conocimiento para su posterior tratamiento).\nEl rol no necesariamente implica el uso de lenguajes de programación, aunque (en el estadío actual del área) suele ser altamente recomendable adquirir su uso. De no contar con ello, es esencial la experiencia en al menos una herramienta de visualización (Tableau, PowerBI, Looker) y uso avanzado de planillas de cálculo (Excel, Google Sheets).\nRetomando lo dicho, es habitual también la necesidad de un cierto de grado de transformación de los datos. En ese aspecto, Python, R y SQL son herramientas de gran ayuda, que desde ya pueden utilizarse más adelante en el análisis como tal. De hecho, su uso se ha consolidado cada vez más de forma mandatoria en términos de poder trabajar con grandes volúmenes de datos y elaborar modelos complejos, inviables de implementar con otras herramientas como las mencionadas anteriormente.\nPosteriormente al análisis, la presentación de los mismos es sumamente importante, y es incluso un diferencial. En ese sentido, un analista de datos completo cuenta con la capacidad para la elaboración de informes y visualizaciones, pudiendo abstraerse de la parte técnica y mostrar efectivamente y de manera sencilla los resultados de su análisis.\nRecapitulando, el análisis de datos pasa a ser hoy un conjunto de conocimientos y técnicas que, con las herramientas adecuadas y enmarcado correctamente en un proceso de analítica de datos, permite la toma de decisiones dentro de las organizaciones a través de la exploración e inferencia de los datos."
  },
  {
    "objectID": "02 - datos unidades y variables.html",
    "href": "02 - datos unidades y variables.html",
    "title": "Datos, unidades y variables de análisis",
    "section": "",
    "text": "Lectura\n\nLos Datos (Estadística Aplicada a las Ciencias Sociales y Humanas: pág. 13 a 15)\nLas Variables (Estadística Aplicada a las Ciencias Sociales y Humanas: pág. 15 a 17)\nLa Primera Organización de los Datos: la matriz de datos (Estadística Aplicada a las Ciencias Sociales y Humanas: pág. 25 a 27)\nTipos de variables (Estadística Aplicada a los Negocios y la Economía: pág. 8 y 9)\nVariables aleatorias (Estadística Aplicada a los Negocios y la Economía: pág. 189 y 190)\nTypes of Data (STAT 414 | Introduction to Probability Theory: lesson 1.4)\nEl concepto de variable aleatoria (Probabilidad y Estadística | Aplicaciones y Métodos: pág. 52 y 53)\n\n\n\nActividades\n\nBusque y analice algún artículo que hable acerca de la diferencia entre datos, información y conocimiento. Provea un ejemplo propio que muestre dicha diferencia.\nConsidere el dataset Top Trends on TikTok & YoutubeShorts. Determine la unidad de análisis, las variables y su tipo. ¿Es alguna de ellas aleatoria?\n\n\n\nResumen\nLos datos son el insumo básico para el análisis de datos. La mínima unidad de información, la materia prima a partir de la cual se produce conocimiento y se pueden tomar acciones basadas en evidencia con cierto grado medible de incertidumbre.\nEs adecuado pensar a un dato como aquello que puede colocarse dentro de una celda (de una planilla); esto es, un número, una letra, una palabra, un verdadero o falso. El hecho de considerar a algo como un dato dependerá del análisis mismo, porque ese dato surgirá como resultado del entrecruzamiento de 2 conceptos sumamente importantes: la unidad de análisis y la variable.\nLa unidad de análisis es el objeto o sujeto sobre el cual se lleva adelante el análisis. La variable es la característica de interés de ese objeto o sujeto, sobre el cual se observará o medirá un dato. La primera suele identificarse como cada una de las filas (de una planilla), la segunda como las columnas (ver imagen); aunque no siempre tiene por qué ser así. La lógica entonces de cualquier análisis de datos será identificar la unidad de análisis, la o las variables de estudio y obtener de estas variables uno o más datos.\n\n\n\n\nvariable 1\nvariable 2\nvariable 3\n\n\n\n\nunidad 1\ndato\ndato\ndato\n\n\nunidad 2\ndato\ndato\ndato\n\n\nunidad 3\ndato\ndato\ndato\n\n\n\nLas variables pueden ser de 2 tipos: cuantitativas o cualitativas. Las primeras, asimismo, pueden ser continuas o discretas, y las segundas, ordinales o nominales. Lo importante de reconocer qué tipo de variable se tiene a la mano está en el hecho de anticipar las técnicas y limitaciones o no para cada caso. Las variables más flexibles y potentes son las cuantitativas continuas porque las mismas pueden discretizarse, ordenarse o transformarse en cualitativas, no así al revés.\nPor otra parte, la clasificación de variables puede implicar no sólo su tipo, sino también si es resultado o no de un proceso aleatorio. Es decir, si es producto del azar en algún punto de su obtención. Esto traerá apareado un cambio completo en el modo de analizar a la variable, así como también de las conclusiones que pueden extraerse.\nRecapitulando, como analista de datos, es sumamente importante participar o tener conocimiento pleno en la definición exhaustiva de la unidad de análisis, del recocimiento de las variables y de la obtención de datos, ya que estos 3 puntos son la base sobre la cual se construye por completo cualquier análisis."
  },
  {
    "objectID": "01 - conceptos y definiciones.html",
    "href": "01 - conceptos y definiciones.html",
    "title": "Conceptos y definiciones",
    "section": "",
    "text": "Lectura\n\nhttps://aws.amazon.com/es/what-is/data-analytics/\nhttps://www.intel.la/content/www/xl/es/artificial-intelligence/what-is-data-analytics.html\nhttps://www.oracle.com/business-analytics/data-analytics/\n\n\n\nActividades\n\n¿Qué es Data Analytics? ¿Considera que es lo mismo que Análisis de Datos?\n¿En qué se diferencia de Big Data Analytics?\n¿Cuáles son los pasos a seguir en un proceso de análisis de datos?\nMencione al menos 3 herramientas vinculadas al análisis de datos\n¿Qué tipo de análisis de datos se pueden hacer?\nRelacione la anterior respuesta con los siguientes conceptos: raw data, information, knowledge, insight, actionable insight, decision-making, model\nDiferencie brevemente Machine Learning, Data Mining, Data Science, Business Intelligence, Data Analysis y Data Analytics\n\n\n\nResumen\nEl análisis de datos es una actividad que se encuentra integrada a otras como ingeniería y ciencia de datos compartiendo conceptos y herramientas, y habitualmente superponiéndose en el día a día de muchas organizaciones. Por esto mismo, como profesional del área, es importante reconocer cuáles son las incumbencias del análisis de datos y cómo se relaciona con el resto del ciclo de vida de los datos.\nSurge entonces la necesidad de definir y comprender conceptos fundamentales para lograr esa distinción. Como suele suceder en otros rubros, varios de estos conceptos son asimilados del inglés y se utilizan diariamente de esta manera, lo que contribuye a la confunsión en algunos casos. Además, las definiciones no siempre son unísonas: dependen de cada autor y evolucionan en el tiempo. Implica así una capacitación y actualización constante.\nComo actividad, el análisis de datos requiere principalmente conocimientos de estadística y de dominio (o de negocio), de tal manera de poder trabajar los datos, obtener conclusiones y traducir esas conclusiones en recomendaciones o acciones (o simplemente producir información / conocimiento para su posterior tratamiento).\nEl rol no necesariamente implica el uso de lenguajes de programación, aunque (en el estadío actual del área) suele ser altamente recomendable adquirir su uso. De no contar con ello, es esencial la experiencia en al menos una herramienta de visualización (Tableau, PowerBI, Looker) y uso avanzado de planillas de cálculo (Excel, Google Sheets).\nRetomando lo dicho, es habitual también la necesidad de un cierto de grado de transformación de los datos. En ese aspecto, Python, R y SQL son herramientas de gran ayuda, que desde ya pueden utilizarse más adelante en el análisis como tal. De hecho, su uso se ha consolidado cada vez más de forma mandatoria en términos de poder trabajar con grandes volúmenes de datos y elaborar modelos complejos, inviables de implementar con otras herramientas como las mencionadas anteriormente.\nPosteriormente al análisis, la presentación de los mismos es sumamente importante, y es incluso un diferencial. En ese sentido, un analista de datos completo cuenta con la capacidad para la elaboración de informes y visualizaciones, pudiendo abstraerse de la parte técnica y mostrar efectivamente y de manera sencilla los resultados de su análisis.\nRecapitulando, el análisis de datos pasa a ser hoy un conjunto de conocimientos y técnicas que, con las herramientas adecuadas y enmarcado correctamente en un proceso de analítica de datos, permite la toma de decisiones dentro de las organizaciones a través de la exploración e inferencia de los datos."
  }
]